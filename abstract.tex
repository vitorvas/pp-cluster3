%Computers have become a fundamental tool at almost every human activity.
%In science, they're ubiquitous and used so widely that are often neglected
%as a complex tool. A professional computer cluster is a good example of
%this situation. Many high-end computers in expensive hardware configuration
%put together using state-of-the-art software tools usually overlooked by
%users as a 'set of computers'. In this paper we present such scientific tool
%in a particular context: a high-end cluster system installed, managed and operated
%by the very same scientific team which employs it on research on the field of Nuclear Engineering.
%This work describes the main features of the LTHN/CDTN (Thermal-hydraulics and Neutronics
%Laboratory/Nuclear Technology Development Center), considering software solutions
%adopted, the impact of it on research currently carried on at the same laboratory
%and the future possible applications of the system. A special attention is given to
%the distributed file-system, a fundamental feature to allow high-performance in a system
%with many physical disk storage units and to the monitoring system. The latter being
%the 'eyes' of the users into the system's load and performance. All solutions adopted for the
%cluster are based on open or free software and almost the totality of the research
%software used is also open or free. Definitely the path towards less expensive
%research, a theme of special interest for scientists and researches from developing countries.

In 2024 the LTHN cluster completed 5 years of operation. There were productive five years, in which
the equipment proved itself invaluable for the research work carried on by the LTHN membres and all
the external members with access to the machine. However, in five years a lot can happen - including
a worldwide pandemic - and the cluster suffered from the effects of time. A couple os SSDs failed,
limited software updates due to the lack of personal and changes on the network of the insitute
where the LTHN cluster is located, among less specific but also detrimental small software failures,
caused a degradation of the service. Less machines operating, ocasional loss of data and problems
on the scheduler were the main problems users of the system faced when running their jobs. With that in
mind, a major updated of the system was carried on and is the subject of this paper, which will
present the main changes and updates made to the system on its sixth year of operation. These changes
are carefully described and will hopefully be of good use for small clusters users and admins. We also
present the performance of the updated system for heavier and more complex simulations run currently
on the LTHN cluster.
